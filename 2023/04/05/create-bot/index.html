<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Hello World | 风雪围城</title>

  
  <meta name="author" content="YueGS">
  

  
  <meta name="description" content="How to Build a Chatbothttps://gpt-index.readthedocs.io/en/latest/guides/tutorials/building_a_chatbot.html
LlamaIndex 是数据和 LLM（large language model）之间的桥梁 ———— 工具集。围绕着数据，你可以使用这个工具集为下游任务（比如基于数据的问答、概述等）创建一个查询接口。">
  

  
  
  <meta name="keywords" content="">
  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  <meta property="og:title" content="Hello World"/>

  <meta property="og:site_name" content="风雪围城"/>

  
  <meta property="og:image" content="/favicon.ico"/>
  

  <link href="/favicon.ico" rel="icon">
  <link rel="alternate" href="/atom.xml" title="风雪围城" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
<div class="blog">
  <div class="content">

    <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">风雪围城</a>
    </h1>
    <p class="site-description"></p>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">Home</a></li>
      
        <li><a href="/archives">Archives</a></li>
      
        <li><a href="/about">About</a></li>
      
    </ul>
  </nav>
</header>

    <main class="site-main posts-loop">
    <article>

  
    
    <h3 class="article-title"><span>Hello World</span></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2023/04/05/create-bot/" rel="bookmark">
        <time class="entry-date published" datetime="2023-04-05T14:56:51.521Z">
          2023-04-05
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p><a target="_blank" rel="noopener" href="https://gpt-index.readthedocs.io/en/latest/guides/tutorials/building_a_chatbot.html">How to Build a Chatbot</a><br><a target="_blank" rel="noopener" href="https://gpt-index.readthedocs.io/en/latest/guides/tutorials/building_a_chatbot.html">https://gpt-index.readthedocs.io/en/latest/guides/tutorials/building_a_chatbot.html</a></p>
<p>LlamaIndex 是数据和 LLM（large language model）之间的桥梁 ———— 工具集。围绕着数据，你可以使用这个工具集为下游任务（比如基于数据的问答、概述等）创建一个查询接口。</p>
<span id="more"></span>

<p>在本文中，我将向你展示如何创建一个增强版的、基于上下文的聊天机器人。<br>我将使用 Langchain 进行底层机器人的抽象；使用 LlamaIndex 进行数据的检索&#x2F;搜索&#x2F;查询。最终，这个机器人可以使用 LlamaIndex 提供的丰富的数据集工具，基于你提供的数据提供问答服务。</p>
<p><a target="_blank" rel="noopener" href="https://medium.com/@jerryjliu98/how-unstructured-and-llamaindex-can-help-bring-the-power-of-llms-to-your-own-data-3657d063e30d">https://medium.com/@jerryjliu98/how-unstructured-and-llamaindex-can-help-bring-the-power-of-llms-to-your-own-data-3657d063e30d</a></p>
<h3 id="上下文"><a href="#上下文" class="headerlink" title="上下文"></a>上下文</h3><p>在本文中，我们将从 Dropbox 中下载原始的 UBER 10-K Html 文档，并基于此数据创建一个 “10-K 机器人”，该机器人将为用户问题提供答案。</p>
<h3 id="数据获取"><a href="#数据获取" class="headerlink" title="数据获取"></a>数据获取</h3><p>我们首先来下载从 2019 年到 2022 年的 10-K 原始文件。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># <span class="doctag">NOTE:</span> the code examples assume you&#x27;re operating within a Jupyter notebook.</span></span><br><span class="line"><span class="comment"># download files</span></span><br><span class="line">!<span class="built_in">mkdir</span> data</span><br><span class="line">!wget <span class="string">&quot;https://www.dropbox.com/s/948jr9cfs7fgj99/UBER.zip?dl=1&quot;</span> -O data/UBER.zip</span><br><span class="line">!unzip data/UBER.zip -d data</span><br></pre></td></tr></table></figure>

<p>首先，使用 <a target="_blank" rel="noopener" href="https://github.com/Unstructured-IO/unstructured">Unstructured</a> 库将 HTML 文件解析成文本。<br>我们可以通过 <a target="_blank" rel="noopener" href="https://llamahub.ai/">LlamaHub</a> 直接集成 Unstructured，LlamaHub 提供了很多工具可以让我们将文本转换为 LlamaIndex 可以使用的 Document 格式。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> download_loader, GPTSimpleVectorIndex, ServiceContext</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line">years = [<span class="number">2022</span>, <span class="number">2021</span>, <span class="number">2020</span>, <span class="number">2019</span>]</span><br><span class="line">UnstructuredReader = download_loader(<span class="string">&quot;UnstructuredReader&quot;</span>, refresh_cache=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">loader = UnstructuredReader()</span><br><span class="line">doc_set = &#123;&#125;</span><br><span class="line">all_docs = []</span><br><span class="line"><span class="keyword">for</span> year <span class="keyword">in</span> years:</span><br><span class="line">    year_docs = loader.load_data(file=Path(<span class="string">f&#x27;./data/UBER/UBER_<span class="subst">&#123;year&#125;</span>.html&#x27;</span>), split_documents=<span class="literal">False</span>)</span><br><span class="line">    <span class="comment"># insert year metadata into each year</span></span><br><span class="line">    <span class="keyword">for</span> d <span class="keyword">in</span> year_docs:</span><br><span class="line">        d.extra_info = &#123;<span class="string">&quot;year&quot;</span>: year&#125;</span><br><span class="line">    doc_set[year] = year_docs</span><br><span class="line">    all_docs.extend(year_docs)</span><br></pre></td></tr></table></figure>

<h3 id="为每一年度创建向量索引"><a href="#为每一年度创建向量索引" class="headerlink" title="为每一年度创建向量索引"></a>为每一年度创建向量索引</h3><p>首先为每一年度的 10-K 报告创建一个向量索引。这允许我们可以指定一个年度进行提问。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># initialize simple vector indices + global vector index</span></span><br><span class="line">service_context = ServiceContext.from_defaults(chunk_size_limit=<span class="number">512</span>)</span><br><span class="line">index_set = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> year <span class="keyword">in</span> years:</span><br><span class="line">    cur_index = GPTSimpleVectorIndex.from_documents(doc_set[year], service_context=service_context)</span><br><span class="line">    index_set[year] = cur_index</span><br><span class="line">    cur_index.save_to_disk(<span class="string">f&#x27;index_<span class="subst">&#123;year&#125;</span>.json&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>上述，我们将索引保存在了本地。我们也可以从本地加载这些索引</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load indices from disk</span></span><br><span class="line">index_set = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> year <span class="keyword">in</span> years:</span><br><span class="line">    cur_index = GPTSimpleVectorIndex.load_from_disk(<span class="string">f&#x27;index_<span class="subst">&#123;year&#125;</span>.json&#x27;</span>)</span><br><span class="line">    index_set[year] = cur_index</span><br></pre></td></tr></table></figure>

<h3 id="将这些向量合成一个图"><a href="#将这些向量合成一个图" class="headerlink" title="将这些向量合成一个图"></a>将这些向量合成一个图</h3><p>问答可以基于所有年份的 10-K 文档。为了达成这一目的，我们将这 4 个向量索引合成一个 “图”。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> llama_index <span class="keyword">import</span> GPTListIndex, LLMPredictor, ServiceContext</span><br><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">from</span> llama_index.indices.composability <span class="keyword">import</span> ComposableGraph</span><br><span class="line"></span><br><span class="line"><span class="comment"># describe each index to help traversal of composed graph</span></span><br><span class="line">index_summaries = [<span class="string">f&quot;UBER 10-k Filing for <span class="subst">&#123;year&#125;</span> fiscal year&quot;</span> <span class="keyword">for</span> year <span class="keyword">in</span> years]</span><br><span class="line"></span><br><span class="line"><span class="comment"># define an LLMPredictor set number of output tokens</span></span><br><span class="line">llm_predictor = LLMPredictor(llm=OpenAI(temperature=<span class="number">0</span>, max_tokens=<span class="number">512</span>))</span><br><span class="line">service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)</span><br><span class="line"></span><br><span class="line"><span class="comment"># define a list index over the vector indices</span></span><br><span class="line"><span class="comment"># allows us to synthesize information across each index</span></span><br><span class="line">graph = ComposableGraph.from_indices(</span><br><span class="line">    GPTListIndex,</span><br><span class="line">    [index_set[y] <span class="keyword">for</span> y <span class="keyword">in</span> years], </span><br><span class="line">    index_summaries=index_summaries,</span><br><span class="line">    service_context=service_context,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># [optional] save to disk</span></span><br><span class="line">graph.save_to_disk(<span class="string">&#x27;10k_graph.json&#x27;</span>)</span><br><span class="line"><span class="comment"># [optional] load from disk, so you don&#x27;t need to build graph from scratch</span></span><br><span class="line">graph = ComposableGraph.load_from_disk(</span><br><span class="line">    <span class="string">&#x27;10k_graph.json&#x27;</span>, </span><br><span class="line">    service_context=service_context,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h3 id=""><a href="#" class="headerlink" title=""></a></h3><p>使用 Langchain 来构建一个外部机器人。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># do imports</span></span><br><span class="line"><span class="keyword">from</span> langchain.agents <span class="keyword">import</span> Tool</span><br><span class="line"><span class="keyword">from</span> langchain.chains.conversation.memory <span class="keyword">import</span> ConversationBufferMemory</span><br><span class="line"><span class="keyword">from</span> langchain.chat_models <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain.agents <span class="keyword">import</span> initialize_agent</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> llama_index.langchain_helpers.agents <span class="keyword">import</span> LlamaToolkit, create_llama_chat_agent, IndexToolConfig, GraphToolConfig</span><br></pre></td></tr></table></figure>

<p>下面，我们为图（graph）定义了一个 <code>GraphToolConfig</code>。注意，我们也同时引入了 <code>DecomposeQueryTransform</code> 模块来使用图中的每一个向量索引，</p>
<h3 id="LangChain"><a href="#LangChain" class="headerlink" title="LangChain"></a>LangChain</h3><p><a target="_blank" rel="noopener" href="https://python.langchain.com/en/latest/index.html">LangChain</a> 是一个框架，用于开发由 语言模型（LM） 驱动的应用程序。<br>理解数据和环境感知是 LangChain 的两个核心原则。</p>
<p>LangChain 包含一下几个模块：</p>
<ul>
<li>Models： LangChain 可以支持各种类型的 Model</li>
<li>Prompts： prompt 管理、prompt 优化、prompt 序列化</li>
<li>Memory：</li>
</ul>
<h4 id="Models"><a href="#Models" class="headerlink" title="Models"></a>Models</h4><h5 id="LLMs"><a href="#LLMs" class="headerlink" title="LLMs"></a>LLMs</h5><p>LLMs 是 LangChain 的核心组件。LangChain 并不是 LLMs 的提供者（LLM provider 包括：OpenAI、Cohere、Hugging Face等），但是提供了和各种 LLMs 交互的标准接口。<br>LLM 类就是用来和各种 LLMs 交互的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line">llm = OpenAI(model_name=<span class="string">&quot;text-ada-001&quot;</span>, n=<span class="number">2</span>, best_of=<span class="number">2</span>)</span><br><span class="line">llm(<span class="string">&quot;Tell me a joke&quot;</span>)</span><br></pre></td></tr></table></figure>

<h5 id="Chat-Models"><a href="#Chat-Models" class="headerlink" title="Chat Models"></a>Chat Models</h5><p>Chat model 的底层还是 LLM，不同的是，它的 API 所暴露出的接口并不是 “文本输入、文本输出” 这种形式，而是使用 “chat message” 作为输入和输出。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chat_models <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> PromptTemplate, LLMChain</span><br><span class="line"><span class="keyword">from</span> langchain.prompts.chat <span class="keyword">import</span> (</span><br><span class="line">    ChatPromptTemplate,</span><br><span class="line">    SystemMessagePromptTemplate,</span><br><span class="line">    AIMessagePromptTemplate,</span><br><span class="line">    HumanMessagePromptTemplate,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> langchain.schema <span class="keyword">import</span> (</span><br><span class="line">    AIMessage,</span><br><span class="line">    HumanMessage,</span><br><span class="line">    SystemMessage</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">chat = ChatOpenAI(temperature=<span class="number">0</span>)</span><br><span class="line">chat([HumanMessage(content=<span class="string">&quot;Translate this sentence from English to French. I love programming.&quot;</span>)])</span><br><span class="line"></span><br><span class="line">messages = [</span><br><span class="line">    SystemMessage(content=<span class="string">&quot;You are a helpful assistant that translates English to French.&quot;</span>),</span><br><span class="line">    HumanMessage(content=<span class="string">&quot;Translate this sentence from English to French. I love programming.&quot;</span>)</span><br><span class="line">]</span><br><span class="line">chat(messages)</span><br></pre></td></tr></table></figure>
<p>如上，可以看出，这种形式可以允许多个输入和输出，可以构建一个上下文。</p>
<p>事实上，也可以通过 <code>MessagePromptTemplate</code> 或者 <code>ChatPromptTemplate</code> 创建 Prompt 模板。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">template=<span class="string">&quot;You are a helpful assistant that translates &#123;input_language&#125; to &#123;output_language&#125;.&quot;</span></span><br><span class="line">system_message_prompt = SystemMessagePromptTemplate.from_template(template)</span><br><span class="line">human_template=<span class="string">&quot;&#123;text&#125;&quot;</span></span><br><span class="line">human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)</span><br><span class="line">chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])</span><br><span class="line"></span><br><span class="line"><span class="comment"># get a chat completion from the formatted messages</span></span><br><span class="line">chat(chat_prompt.format_prompt(input_language=<span class="string">&quot;English&quot;</span>, output_language=<span class="string">&quot;French&quot;</span>, text=<span class="string">&quot;I love programming.&quot;</span>).to_messages())</span><br></pre></td></tr></table></figure>

<p>进一步的，也可以使用 <code>LLMChain</code> 来简化上面的问答</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chain = LLMChain(llm=chat, prompt=chat_prompt)</span><br><span class="line">chain.run(input_language=<span class="string">&quot;English&quot;</span>, output_language=<span class="string">&quot;French&quot;</span>, text=<span class="string">&quot;I love programming.&quot;</span>)</span><br></pre></td></tr></table></figure>


<h5 id="Text-Embedding-Models"><a href="#Text-Embedding-Models" class="headerlink" title="Text Embedding Models"></a>Text Embedding Models</h5><p>Embedding 提供了和具体的 embeddings（OpenAI、Cohere、Hugging Face 等都是具体 embeddings 的提供者） 交互的标准接口。<br>Embeddings 将文本转化为向量，即文本作为输入，浮点数组作为输出。这样我们就可以在向量空间中考虑文本，利用向量空间的特性，我们可以找到最相近的两个文本。</p>
<p>LangChain 中，一个 Embedding 对象有两个公开的方法：<code>embed_documents</code> 和 <code>embed_query</code>。这两个方法最大的区别就是 一个是针对多个文档，一个针对单个文档。<br>以下，我们以 OpenAI 为例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.embeddings <span class="keyword">import</span> OpenAIEmbeddings</span><br><span class="line">embeddings = OpenAIEmbeddings()</span><br><span class="line">text = <span class="string">&quot;This is a test document.&quot;</span></span><br><span class="line">query_result = embeddings.embed_query(text)</span><br><span class="line"></span><br><span class="line">doc_result = embeddings.embed_documents([text])</span><br></pre></td></tr></table></figure>

<h3 id="Prompts"><a href="#Prompts" class="headerlink" title="Prompts"></a>Prompts</h3><p>Prompt 代表着 model 的输入。LangChain 提供了几个类可以快速构建出一个 Prompt，比如 PromptTemplate。</p>
<h4 id="LLM-Prompt-Templates"><a href="#LLM-Prompt-Templates" class="headerlink" title="LLM Prompt Templates"></a>LLM Prompt Templates</h4><p>一个 Prompt 通产包括：</p>
<ul>
<li>指令；</li>
<li>少量示例，以帮助模型产生更好的答案；</li>
<li>问题</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> PromptTemplate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">template = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">I want you to act as a naming consultant for new companies.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Here are some examples of good company names:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">- search engine, Google</span></span><br><span class="line"><span class="string">- social media, Facebook</span></span><br><span class="line"><span class="string">- video sharing, YouTube</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">The name should be short, catchy and easy to remember.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">What is a good name for a company that makes &#123;product&#125;?</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;product&quot;</span>],</span><br><span class="line">    template=template,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>如上，可以在 Prompt 模板中设置若干个输入变量。</p>
<p>为了能够让语言模型给出更好的答案，我们可以给模型提供更多的示例。这时候，就可以使用 <code>FewShotPromptTemplate</code>，它实际上也是使用了一个 PromptTemplate 和一组示例。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> PromptTemplate, FewShotPromptTemplate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># First, create the list of few shot examples.</span></span><br><span class="line"><span class="comment"># 创建示例</span></span><br><span class="line">examples = [</span><br><span class="line">    &#123;<span class="string">&quot;word&quot;</span>: <span class="string">&quot;happy&quot;</span>, <span class="string">&quot;antonym&quot;</span>: <span class="string">&quot;sad&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;word&quot;</span>: <span class="string">&quot;tall&quot;</span>, <span class="string">&quot;antonym&quot;</span>: <span class="string">&quot;short&quot;</span>&#125;,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Next, we specify the template to format the examples we have provided.</span></span><br><span class="line"><span class="comment"># We use the `PromptTemplate` class for this.</span></span><br><span class="line"><span class="comment"># 指定模板</span></span><br><span class="line">example_formatter_template = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Word: &#123;word&#125;</span></span><br><span class="line"><span class="string">Antonym: &#123;antonym&#125;\n</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">example_prompt = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;word&quot;</span>, <span class="string">&quot;antonym&quot;</span>],</span><br><span class="line">    template=example_formatter_template,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Finally, we create the `FewShotPromptTemplate` object.</span></span><br><span class="line"><span class="comment"># 创建 FewShotPromptTemplate 对象</span></span><br><span class="line">few_shot_prompt = FewShotPromptTemplate(</span><br><span class="line">    <span class="comment"># These are the examples we want to insert into the prompt.</span></span><br><span class="line">    examples=examples,</span><br><span class="line">    <span class="comment"># This is how we want to format the examples when we insert them into the prompt.</span></span><br><span class="line">    example_prompt=example_prompt,</span><br><span class="line">    <span class="comment"># The prefix is some text that goes before the examples in the prompt.</span></span><br><span class="line">    <span class="comment"># Usually, this consists of intructions.</span></span><br><span class="line">    prefix=<span class="string">&quot;Give the antonym of every input&quot;</span>,</span><br><span class="line">    <span class="comment"># The suffix is some text that goes after the examples in the prompt.</span></span><br><span class="line">    <span class="comment"># Usually, this is where the user input will go</span></span><br><span class="line">    suffix=<span class="string">&quot;Word: &#123;input&#125;\nAntonym:&quot;</span>,</span><br><span class="line">    <span class="comment"># The input variables are the variables that the overall prompt expects.</span></span><br><span class="line">    input_variables=[<span class="string">&quot;input&quot;</span>],</span><br><span class="line">    <span class="comment"># The example_separator is the string we will use to join the prefix, examples, and suffix together with.</span></span><br><span class="line">    example_separator=<span class="string">&quot;\n\n&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># We can now generate a prompt using the `format` method.</span></span><br><span class="line"><span class="built_in">print</span>(few_shot_prompt.<span class="built_in">format</span>(<span class="built_in">input</span>=<span class="string">&quot;big&quot;</span>))</span><br><span class="line"><span class="comment"># -&gt; Give the antonym of every input</span></span><br><span class="line"><span class="comment"># -&gt; </span></span><br><span class="line"><span class="comment"># -&gt; Word: happy</span></span><br><span class="line"><span class="comment"># -&gt; Antonym: sad</span></span><br><span class="line"><span class="comment"># -&gt;</span></span><br><span class="line"><span class="comment"># -&gt; Word: tall</span></span><br><span class="line"><span class="comment"># -&gt; Antonym: short</span></span><br><span class="line"><span class="comment"># -&gt;</span></span><br><span class="line"><span class="comment"># -&gt; Word: big</span></span><br><span class="line"><span class="comment"># -&gt; Antonym:</span></span><br></pre></td></tr></table></figure>

<h4 id="Chat-Prompt-Templetes"><a href="#Chat-Prompt-Templetes" class="headerlink" title="Chat Prompt Templetes"></a>Chat Prompt Templetes</h4><p>Chat Models 使用一组 chat message 作为输入。相应的，可以使用 <code>MessagePromptTemplate</code> 作为一个 chat message 的 prompt 模板，而 <code>ChatPromptTemplate</code> 可以包含有多个 <code>MessagePromptTemplate</code>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> (</span><br><span class="line">    ChatPromptTemplate,</span><br><span class="line">    PromptTemplate,</span><br><span class="line">    SystemMessagePromptTemplate,</span><br><span class="line">    AIMessagePromptTemplate,</span><br><span class="line">    HumanMessagePromptTemplate,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> langchain.schema <span class="keyword">import</span> (</span><br><span class="line">    AIMessage,</span><br><span class="line">    HumanMessage,</span><br><span class="line">    SystemMessage</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">template=<span class="string">&quot;You are a helpful assistant that translates &#123;input_language&#125; to &#123;output_language&#125;.&quot;</span></span><br><span class="line">system_message_prompt = SystemMessagePromptTemplate.from_template(template)</span><br><span class="line">human_template=<span class="string">&quot;&#123;text&#125;&quot;</span></span><br><span class="line">human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)</span><br><span class="line"></span><br><span class="line">chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])</span><br><span class="line"></span><br><span class="line"><span class="comment"># get a chat completion from the formatted messages</span></span><br><span class="line">chat_prompt.format_prompt(input_language=<span class="string">&quot;English&quot;</span>, output_language=<span class="string">&quot;French&quot;</span>, text=<span class="string">&quot;I love programming.&quot;</span>).to_messages()</span><br></pre></td></tr></table></figure>



<h4 id="Example-Seletors"><a href="#Example-Seletors" class="headerlink" title="Example Seletors"></a>Example Seletors</h4><p>我们也可以创建一个示例库，在需要的时候从中选择其中若干个到 Prompt 中。ExampleSelector 就是负责做这类事情的。<br>基本的 ExampleSelector 信息定义如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BaseExampleSelector</span>(<span class="title class_ inherited__">ABC</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Interface for selecting examples to include in prompts.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @abstractmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">select_examples</span>(<span class="params">self, input_variables: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">str</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">dict</span>]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Select which examples to use based on the inputs.&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>如上，我们需要实现 <code>select_examples</code> 方法。接下来，让我们实现一个：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts.example_selector.base <span class="keyword">import</span> BaseExampleSelector</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Dict</span>, <span class="type">List</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CustomExampleSelector</span>(<span class="title class_ inherited__">BaseExampleSelector</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, examples: <span class="type">List</span>[<span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">str</span>]]</span>):</span><br><span class="line">        self.examples = examples</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_example</span>(<span class="params">self, example: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">str</span>]</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Add new example to store for a key.&quot;&quot;&quot;</span></span><br><span class="line">        self.examples.append(example)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">select_examples</span>(<span class="params">self, input_variables: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">str</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">dict</span>]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Select which examples to use based on the inputs.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> np.random.choice(self.examples, size=<span class="number">2</span>, replace=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">examples = [</span><br><span class="line">    &#123;<span class="string">&quot;foo&quot;</span>: <span class="string">&quot;1&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;foo&quot;</span>: <span class="string">&quot;2&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;foo&quot;</span>: <span class="string">&quot;3&quot;</span>&#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize example selector.</span></span><br><span class="line">example_selector = CustomExampleSelector(examples)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Select examples</span></span><br><span class="line">example_selector.select_examples(&#123;<span class="string">&quot;foo&quot;</span>: <span class="string">&quot;foo&quot;</span>&#125;)</span><br><span class="line"><span class="comment"># -&gt; array([&#123;&#x27;foo&#x27;: &#x27;2&#x27;&#125;, &#123;&#x27;foo&#x27;: &#x27;3&#x27;&#125;], dtype=object)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Add new example to the set of examples</span></span><br><span class="line">example_selector.add_example(&#123;<span class="string">&quot;foo&quot;</span>: <span class="string">&quot;4&quot;</span>&#125;)</span><br><span class="line">example_selector.examples</span><br><span class="line"><span class="comment"># -&gt; [&#123;&#x27;foo&#x27;: &#x27;1&#x27;&#125;, &#123;&#x27;foo&#x27;: &#x27;2&#x27;&#125;, &#123;&#x27;foo&#x27;: &#x27;3&#x27;&#125;, &#123;&#x27;foo&#x27;: &#x27;4&#x27;&#125;]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Select examples</span></span><br><span class="line">example_selector.select_examples(&#123;<span class="string">&quot;foo&quot;</span>: <span class="string">&quot;foo&quot;</span>&#125;)</span><br><span class="line"><span class="comment"># -&gt; array([&#123;&#x27;foo&#x27;: &#x27;1&#x27;&#125;, &#123;&#x27;foo&#x27;: &#x27;4&#x27;&#125;], dtype=object)</span></span><br></pre></td></tr></table></figure>


<h3 id="Indexes"><a href="#Indexes" class="headerlink" title="Indexes"></a>Indexes</h3><p>通过 Indexes，可以构建和 LLMs 更好地与 documents 进行交互。<br>indexes 最常用在检索中。<br>可以通过 <code>BaseRetriever</code> 来了解 Retriever 的定义：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> abc <span class="keyword">import</span> ABC, abstractmethod</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span></span><br><span class="line"><span class="keyword">from</span> langchain.schema <span class="keyword">import</span> Document</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BaseRetriever</span>(<span class="title class_ inherited__">ABC</span>):</span><br><span class="line"><span class="meta">    @abstractmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_relevant_documents</span>(<span class="params">self, query: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[Document]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Get texts relevant for a query.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            query: string to find relevant texts for</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            List of relevant documents</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p>默认情况下，LangChain 使用 <a target="_blank" rel="noopener" href="https://python.langchain.com/en/latest/ecosystem/chroma.html"><code>Chroma</code></a> 作为向量存储索引，我们也使用它来完成 indexes 的应用实例。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install chromadb </span><br></pre></td></tr></table></figure>
<p>关于 documents 的问答，通常包括四个步骤：</p>
<ul>
<li>创建索引</li>
<li>为该索引创建一个检索器 Retriever</li>
<li>创建问答链</li>
<li>问问题</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> RetrievalQA</span><br><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain.document_loaders <span class="keyword">import</span> TextLoader</span><br><span class="line">loader = TextLoader(<span class="string">&#x27;../state_of_the_union.txt&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>接下来创建索引</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.indexes <span class="keyword">import</span> VectorstoreIndexCreator</span><br><span class="line"></span><br><span class="line">index = VectorstoreIndexCreator().from_loaders([loader])</span><br></pre></td></tr></table></figure>
<p>index 已经被创建，现在我们就可以使用它来提问了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">query = <span class="string">&quot;What did the president say about Ketanji Brown Jackson&quot;</span></span><br><span class="line">index.query(query)</span><br><span class="line"></span><br><span class="line">query = <span class="string">&quot;What did the president say about Ketanji Brown Jackson&quot;</span></span><br><span class="line">index.query_with_sources(query)</span><br></pre></td></tr></table></figure>

<p><code>VectorstoreIndexCreator</code> 做了什么呢？<br>当 documents 被载入后：</p>
<ol>
<li>把 documents 分割成块，即若干个 document；</li>
<li>为每个 document 创建一个 embeddings；</li>
<li>在 vectorstore 中存储 documents 和 embeddings。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> CharacterTextSplitter</span><br><span class="line"><span class="keyword">from</span> langchain.embeddings <span class="keyword">import</span> OpenAIEmbeddings</span><br><span class="line"><span class="keyword">from</span> langchain.vectorstores <span class="keyword">import</span> Chroma</span><br><span class="line"></span><br><span class="line">text_splitter = CharacterTextSplitter(chunk_size=<span class="number">1000</span>, chunk_overlap=<span class="number">0</span>)</span><br><span class="line">documents = loader.load()</span><br><span class="line">texts = text_splitter.split_documents(documents)</span><br><span class="line">embeddings = OpenAIEmbeddings()</span><br><span class="line"></span><br><span class="line">db = Chroma.from_documents(texts, embeddings)</span><br><span class="line"><span class="comment"># 通过 retriever 暴露 index</span></span><br><span class="line">retriever = db.as_retriever()</span><br><span class="line"></span><br><span class="line">qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=<span class="string">&quot;stuff&quot;</span>, retriever=retriever)</span><br><span class="line"></span><br><span class="line">query = <span class="string">&quot;What did the president say about Ketanji Brown Jackson&quot;</span></span><br><span class="line">qa.run(query)</span><br></pre></td></tr></table></figure>

<p><code>VectorstoreIndexCreator</code> 实际上就是上述逻辑的封装。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">index_creator = VectorstoreIndexCreator(</span><br><span class="line">    vectorstore_cls=Chroma, </span><br><span class="line">    embedding=OpenAIEmbeddings(),</span><br><span class="line">    text_splitter=CharacterTextSplitter(chunk_size=<span class="number">1000</span>, chunk_overlap=<span class="number">0</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h3 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h3><h3 id="Chains"><a href="#Chains" class="headerlink" title="Chains"></a>Chains</h3><p>单独使用 LLM 完成一个简单的示例是没有问题的，但通常，更复杂的环境下，我们需要链式的 LLMs。<br>Chains 允许我们将多个组件组合在一起，创建一个单一的、连贯的应用。比如，我们可以创建一个使用 <code>PromptTemplate</code> 对用户输入进行格式化，将格式化后的数据传入到 LLM，最后接受格式化输出的链。<br>LangChain 提供了 Chains 的标准接口，以及一些通用的功能。LLMChain 就是一个简单的 Chain 的实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> LLMChain</span><br><span class="line"><span class="keyword">from</span> langchain.chat_models <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain.prompts.chat <span class="keyword">import</span> (</span><br><span class="line">    ChatPromptTemplate,</span><br><span class="line">    HumanMessagePromptTemplate,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">llm = OpenAI(temperature=<span class="number">0.9</span>)</span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;product&quot;</span>],</span><br><span class="line">    template=<span class="string">&quot;What is a good name for a company that makes &#123;product&#125;?&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">chain = LLMChain(llm=llm, prompt=prompt)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run the chain only specifying the input variable.</span></span><br><span class="line"><span class="built_in">print</span>(chain.run(<span class="string">&quot;colorful socks&quot;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">human_message_prompt = HumanMessagePromptTemplate(</span><br><span class="line">        prompt=PromptTemplate(</span><br><span class="line">            template=<span class="string">&quot;What is a good name for a company that makes &#123;product&#125;?&quot;</span>,</span><br><span class="line">            input_variables=[<span class="string">&quot;product&quot;</span>],</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line">chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])</span><br><span class="line">chat = ChatOpenAI(temperature=<span class="number">0.9</span>)</span><br><span class="line">chain = LLMChain(llm=chat, prompt=chat_prompt_template)</span><br><span class="line"><span class="built_in">print</span>(chain.run(<span class="string">&quot;colorful socks&quot;</span>))</span><br></pre></td></tr></table></figure>

<p>也可以通过将多个链组合在一起，构建一个更加复杂的链。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> SimpleSequentialChain</span><br><span class="line"></span><br><span class="line">second_prompt = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;company_name&quot;</span>],</span><br><span class="line">    template=<span class="string">&quot;Write a catchphrase for the following company: &#123;company_name&#125;&quot;</span>,</span><br><span class="line">)</span><br><span class="line">chain_two = LLMChain(llm=llm, prompt=second_prompt)</span><br><span class="line"></span><br><span class="line">overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run the chain specifying only the input variable for the first chain.</span></span><br><span class="line">catchphrase = overall_chain.run(<span class="string">&quot;colorful socks&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(catchphrase)</span><br></pre></td></tr></table></figure>


<h3 id="Agents"><a href="#Agents" class="headerlink" title="Agents"></a>Agents</h3>
      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    

    </div>

    
  </div>
</article>

  









    </main>

    <footer class="site-footer">
  <p class="site-info">
    
    &copy; 2023 YueGS
    
  </p>
</footer>
    
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-116967169-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-116967169-1');
</script>

    
  </div>
</div>
</body>
</html>