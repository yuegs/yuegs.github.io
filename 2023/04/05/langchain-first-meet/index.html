<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>LangChain 初识 | 风雪围城</title>

  
  <meta name="author" content="YueGS">
  

  
  <meta name="description" content="随着 OpenAI 的兴起，LLM 仿佛是在一夜之间，忽然闯入到普通人的生活。我们该如何和它对话，如何把它带入到这个现实世界，类似 LangChain 这样的框架，或许给我们提供了一整套的解决方案。
LangChain 初次见面，这里，先去认识它的基本概念。">
  

  
  
  <meta name="keywords" content="LangChain,OpenAI,LLM">
  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  <meta property="og:title" content="LangChain 初识"/>

  <meta property="og:site_name" content="风雪围城"/>

  
  <meta property="og:image" content="/favicon.ico"/>
  

  <link href="/favicon.ico" rel="icon">
  <link rel="alternate" href="/atom.xml" title="风雪围城" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
<div class="blog">
  <div class="content">

    <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">风雪围城</a>
    </h1>
    <p class="site-description"></p>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">Home</a></li>
      
        <li><a href="/archives">Archives</a></li>
      
        <li><a href="/about">About</a></li>
      
    </ul>
  </nav>
</header>

    <main class="site-main posts-loop">
    <article>

  
    
    <h3 class="article-title"><span>LangChain 初识</span></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2023/04/05/langchain-first-meet/" rel="bookmark">
        <time class="entry-date published" datetime="2023-04-05T14:56:51.521Z">
          2023-04-05
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p><img src="https://images.kinorium.com/movie/shot/151475/w1500_237680.jpg"></p>
<p>随着 OpenAI 的兴起，LLM 仿佛是在一夜之间，忽然闯入到普通人的生活。我们该如何和它对话，如何把它带入到这个现实世界，类似 LangChain 这样的框架，或许给我们提供了一整套的解决方案。</p>
<p>LangChain 初次见面，这里，先去认识它的基本概念。</p>
<span id="more"></span>

<h2 id="LangChain"><a href="#LangChain" class="headerlink" title="LangChain"></a>LangChain</h2><p><a target="_blank" rel="noopener" href="https://python.langchain.com/en/latest/index.html">LangChain</a> 是一个框架，用于开发由 语言模型（LM） 驱动的应用程序。<br>理解数据和环境感知是 LangChain 的两个核心原则。</p>
<!--more-->

<p>LangChain 包含以下几个模块：</p>
<ul>
<li><p>Models：LangChain 提供了和主流 Model 交互的标准接口。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line">llm = OpenAI(temperature=<span class="number">0.9</span>)</span><br><span class="line">text = <span class="string">&quot;What would be a good company name for a company that makes colorful socks?&quot;</span></span><br><span class="line"><span class="built_in">print</span>(llm(text))</span><br></pre></td></tr></table></figure>


</li>
<li><p>Prompts：Prompt 提供了对用户输入的封装，并提供了输入的环境，让模型在处理时能够更加<strong><strong>聚焦问题本身</strong></strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;product&quot;</span>],</span><br><span class="line">    template=<span class="string">&quot;What is a good name for a company that makes &#123;product&#125;?&quot;</span>,</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(prompt.<span class="built_in">format</span>(product=<span class="string">&quot;colorful socks&quot;</span>))</span><br><span class="line">llm(prompt)</span><br></pre></td></tr></table></figure>
<p>以上，Model 和 Prompt 就构成了最简单的 LLM 应用。<br><img src="https://pbs.twimg.com/media/FiNtxGuUUAIo6f_?format=jpg&name=medium"> </p>
</li>
<li><p>Memory：LLM 和 Chains 是无状态的，但是在某些应用下，我们又需要一个上下文，这就是 Memory 出现的意义。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> OpenAI, ConversationChain</span><br><span class="line"></span><br><span class="line">llm = OpenAI(temperature=<span class="number">0</span>)</span><br><span class="line">conversation = ConversationChain(llm=llm, verbose=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">conversation.predict(<span class="built_in">input</span>=<span class="string">&quot;Hi there!&quot;</span>)</span><br><span class="line">conversation.predict(<span class="built_in">input</span>=<span class="string">&quot;I&#x27;m doing well! Just having a conversation with an AI.&quot;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>Indexes：在基于私域数据使用语言模型的时候，向量索引将是一个很强大的工具。向量索引提供了文本相关性的比较策略，基于该策略，问答可以是私域数据相关的。</p>
</li>
<li><p>Chains：一系列顺序地调用，就是一个链。在链上的组件可以是一个 LLM 或者其他工具。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> LLMChain</span><br><span class="line"></span><br><span class="line">llm = OpenAI(temperature=<span class="number">0.9</span>)</span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;product&quot;</span>],</span><br><span class="line">    template=<span class="string">&quot;What is a good name for a company that makes &#123;product&#125;?&quot;</span>,</span><br><span class="line">)</span><br><span class="line">chain = LLMChain(llm=llm, prompt=prompt)</span><br><span class="line">chain.run(<span class="string">&quot;colorful socks&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>通过 Chain 我们可以完成一些更加复杂的工作。上述就是简单的示例：将 prompt 和模型 llm 链接在一起。事实上，我们也可以将不同的信息源或者 LLM 链接起来构成一个更加复杂、明确的调用链。</p>
</li>
</ul>
<p><img src="https://pbs.twimg.com/media/FiNvARnUAAA2tSU?format=jpg&name=medium"></p>
<ul>
<li>Agents：Agents 可以处理更加复杂的工作。在 Agent 中封装更加复杂的逻辑，可以让 Agent 去决定调用哪些 LLM 、工具甚至别的 Agent。</li>
</ul>
<p><img src="https://pbs.twimg.com/media/FiNwAiOVQAEP28g?format=jpg&name=medium"></p>
<h3 id="Models"><a href="#Models" class="headerlink" title="Models"></a>Models</h3><h4 id="LLMs"><a href="#LLMs" class="headerlink" title="LLMs"></a>LLMs</h4><p>LLMs 是 LangChain 的核心组件。LangChain 并不是 LLMs 的提供者（LLM provider 包括：OpenAI、Cohere、Hugging Face等），但是提供了和各种 LLMs 交互的标准接口。<br>LLM 类就是用来和各种 LLMs 交互的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line">llm = OpenAI(model_name=<span class="string">&quot;text-ada-001&quot;</span>, n=<span class="number">2</span>, best_of=<span class="number">2</span>)</span><br><span class="line">llm(<span class="string">&quot;Tell me a joke&quot;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="Chat-Models"><a href="#Chat-Models" class="headerlink" title="Chat Models"></a>Chat Models</h4><p>Chat model 的底层还是 LLM，不同的是，它的 API 所暴露出的接口并不是 “文本输入、文本输出” 这种形式，而是使用 “chat message” 作为输入和输出。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chat_models <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> PromptTemplate, LLMChain</span><br><span class="line"><span class="keyword">from</span> langchain.prompts.chat <span class="keyword">import</span> (</span><br><span class="line">    ChatPromptTemplate,</span><br><span class="line">    SystemMessagePromptTemplate,</span><br><span class="line">    AIMessagePromptTemplate,</span><br><span class="line">    HumanMessagePromptTemplate,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> langchain.schema <span class="keyword">import</span> (</span><br><span class="line">    AIMessage,</span><br><span class="line">    HumanMessage,</span><br><span class="line">    SystemMessage</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">chat = ChatOpenAI(temperature=<span class="number">0</span>)</span><br><span class="line">chat([HumanMessage(content=<span class="string">&quot;Translate this sentence from English to French. I love programming.&quot;</span>)])</span><br><span class="line"></span><br><span class="line">messages = [</span><br><span class="line">    SystemMessage(content=<span class="string">&quot;You are a helpful assistant that translates English to French.&quot;</span>),</span><br><span class="line">    HumanMessage(content=<span class="string">&quot;Translate this sentence from English to French. I love programming.&quot;</span>)</span><br><span class="line">]</span><br><span class="line">chat(messages)</span><br></pre></td></tr></table></figure>
<p>如上，可以看出，这种形式可以允许多个输入和输出，可以构建一个上下文。</p>
<p>事实上，也可以通过 <code>MessagePromptTemplate</code> 或者 <code>ChatPromptTemplate</code> 创建 Prompt 模板。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">template=<span class="string">&quot;You are a helpful assistant that translates &#123;input_language&#125; to &#123;output_language&#125;.&quot;</span></span><br><span class="line">system_message_prompt = SystemMessagePromptTemplate.from_template(template)</span><br><span class="line">human_template=<span class="string">&quot;&#123;text&#125;&quot;</span></span><br><span class="line">human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)</span><br><span class="line">chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])</span><br><span class="line"></span><br><span class="line"><span class="comment"># get a chat completion from the formatted messages</span></span><br><span class="line">chat(chat_prompt.format_prompt(input_language=<span class="string">&quot;English&quot;</span>, output_language=<span class="string">&quot;French&quot;</span>, text=<span class="string">&quot;I love programming.&quot;</span>).to_messages())</span><br></pre></td></tr></table></figure>

<p>进一步的，也可以使用 <code>LLMChain</code> 来简化上面的问答</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chain = LLMChain(llm=chat, prompt=chat_prompt)</span><br><span class="line">chain.run(input_language=<span class="string">&quot;English&quot;</span>, output_language=<span class="string">&quot;French&quot;</span>, text=<span class="string">&quot;I love programming.&quot;</span>)</span><br></pre></td></tr></table></figure>


<h4 id="Text-Embedding-Models"><a href="#Text-Embedding-Models" class="headerlink" title="Text Embedding Models"></a>Text Embedding Models</h4><p>Embedding 提供了和具体的 embeddings（OpenAI、Cohere、Hugging Face 等都是具体 embeddings 的提供者） 交互的标准接口。<br>Embeddings 将文本转化为向量，即文本作为输入，浮点数组作为输出。这样我们就可以在向量空间中考虑文本，利用向量空间的特性，我们可以找到最相近的两个文本。</p>
<p>LangChain 中，一个 Embedding 对象有两个公开的方法：<code>embed_documents</code> 和 <code>embed_query</code>。这两个方法最大的区别就是 一个是针对多个文档，一个针对单个文档。<br>以下，我们以 OpenAI 为例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.embeddings <span class="keyword">import</span> OpenAIEmbeddings</span><br><span class="line">embeddings = OpenAIEmbeddings()</span><br><span class="line">text = <span class="string">&quot;This is a test document.&quot;</span></span><br><span class="line">query_result = embeddings.embed_query(text)</span><br><span class="line"></span><br><span class="line">doc_result = embeddings.embed_documents([text])</span><br></pre></td></tr></table></figure>

<h2 id="Prompts"><a href="#Prompts" class="headerlink" title="Prompts"></a>Prompts</h2><p>Prompt 代表着 model 的输入。LangChain 提供了几个类可以快速构建出一个 Prompt，比如 PromptTemplate。</p>
<h3 id="LLM-Prompt-Templates"><a href="#LLM-Prompt-Templates" class="headerlink" title="LLM Prompt Templates"></a>LLM Prompt Templates</h3><p>一个 Prompt 通产包括：</p>
<ul>
<li>指令</li>
<li>少量示例，以帮助模型产生更好的答案</li>
<li>问题</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> PromptTemplate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">template = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">I want you to act as a naming consultant for new companies.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Here are some examples of good company names:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">- search engine, Google</span></span><br><span class="line"><span class="string">- social media, Facebook</span></span><br><span class="line"><span class="string">- video sharing, YouTube</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">The name should be short, catchy and easy to remember.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">What is a good name for a company that makes &#123;product&#125;?</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;product&quot;</span>],</span><br><span class="line">    template=template,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>如上，可以在 Prompt 模板中设置若干个输入变量。</p>
<p>为了能够让语言模型给出更好的答案，我们可以给模型提供更多的示例。这时候，就可以使用 <code>FewShotPromptTemplate</code>，它实际上也是使用了一个 PromptTemplate 和一组示例。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> PromptTemplate, FewShotPromptTemplate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># First, create the list of few shot examples.</span></span><br><span class="line"><span class="comment"># 创建示例</span></span><br><span class="line">examples = [</span><br><span class="line">    &#123;<span class="string">&quot;word&quot;</span>: <span class="string">&quot;happy&quot;</span>, <span class="string">&quot;antonym&quot;</span>: <span class="string">&quot;sad&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;word&quot;</span>: <span class="string">&quot;tall&quot;</span>, <span class="string">&quot;antonym&quot;</span>: <span class="string">&quot;short&quot;</span>&#125;,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Next, we specify the template to format the examples we have provided.</span></span><br><span class="line"><span class="comment"># We use the `PromptTemplate` class for this.</span></span><br><span class="line"><span class="comment"># 指定模板</span></span><br><span class="line">example_formatter_template = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Word: &#123;word&#125;</span></span><br><span class="line"><span class="string">Antonym: &#123;antonym&#125;\n</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">example_prompt = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;word&quot;</span>, <span class="string">&quot;antonym&quot;</span>],</span><br><span class="line">    template=example_formatter_template,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Finally, we create the `FewShotPromptTemplate` object.</span></span><br><span class="line"><span class="comment"># 创建 FewShotPromptTemplate 对象</span></span><br><span class="line">few_shot_prompt = FewShotPromptTemplate(</span><br><span class="line">    <span class="comment"># These are the examples we want to insert into the prompt.</span></span><br><span class="line">    examples=examples,</span><br><span class="line">    <span class="comment"># This is how we want to format the examples when we insert them into the prompt.</span></span><br><span class="line">    example_prompt=example_prompt,</span><br><span class="line">    <span class="comment"># The prefix is some text that goes before the examples in the prompt.</span></span><br><span class="line">    <span class="comment"># Usually, this consists of intructions.</span></span><br><span class="line">    prefix=<span class="string">&quot;Give the antonym of every input&quot;</span>,</span><br><span class="line">    <span class="comment"># The suffix is some text that goes after the examples in the prompt.</span></span><br><span class="line">    <span class="comment"># Usually, this is where the user input will go</span></span><br><span class="line">    suffix=<span class="string">&quot;Word: &#123;input&#125;\nAntonym:&quot;</span>,</span><br><span class="line">    <span class="comment"># The input variables are the variables that the overall prompt expects.</span></span><br><span class="line">    input_variables=[<span class="string">&quot;input&quot;</span>],</span><br><span class="line">    <span class="comment"># The example_separator is the string we will use to join the prefix, examples, and suffix together with.</span></span><br><span class="line">    example_separator=<span class="string">&quot;\n\n&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># We can now generate a prompt using the `format` method.</span></span><br><span class="line"><span class="built_in">print</span>(few_shot_prompt.<span class="built_in">format</span>(<span class="built_in">input</span>=<span class="string">&quot;big&quot;</span>))</span><br><span class="line"><span class="comment"># -&gt; Give the antonym of every input</span></span><br><span class="line"><span class="comment"># -&gt; </span></span><br><span class="line"><span class="comment"># -&gt; Word: happy</span></span><br><span class="line"><span class="comment"># -&gt; Antonym: sad</span></span><br><span class="line"><span class="comment"># -&gt;</span></span><br><span class="line"><span class="comment"># -&gt; Word: tall</span></span><br><span class="line"><span class="comment"># -&gt; Antonym: short</span></span><br><span class="line"><span class="comment"># -&gt;</span></span><br><span class="line"><span class="comment"># -&gt; Word: big</span></span><br><span class="line"><span class="comment"># -&gt; Antonym:</span></span><br></pre></td></tr></table></figure>

<h3 id="Chat-Prompt-Templetes"><a href="#Chat-Prompt-Templetes" class="headerlink" title="Chat Prompt Templetes"></a>Chat Prompt Templetes</h3><p>Chat Models 使用一组 chat message 作为输入。相应的，可以使用 <code>MessagePromptTemplate</code> 作为一个 chat message 的 prompt 模板，而 <code>ChatPromptTemplate</code> 可以包含有多个 <code>MessagePromptTemplate</code>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> (</span><br><span class="line">    ChatPromptTemplate,</span><br><span class="line">    PromptTemplate,</span><br><span class="line">    SystemMessagePromptTemplate,</span><br><span class="line">    AIMessagePromptTemplate,</span><br><span class="line">    HumanMessagePromptTemplate,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> langchain.schema <span class="keyword">import</span> (</span><br><span class="line">    AIMessage,</span><br><span class="line">    HumanMessage,</span><br><span class="line">    SystemMessage</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">template=<span class="string">&quot;You are a helpful assistant that translates &#123;input_language&#125; to &#123;output_language&#125;.&quot;</span></span><br><span class="line">system_message_prompt = SystemMessagePromptTemplate.from_template(template)</span><br><span class="line">human_template=<span class="string">&quot;&#123;text&#125;&quot;</span></span><br><span class="line">human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)</span><br><span class="line"></span><br><span class="line">chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])</span><br><span class="line"></span><br><span class="line"><span class="comment"># get a chat completion from the formatted messages</span></span><br><span class="line">chat_prompt.format_prompt(input_language=<span class="string">&quot;English&quot;</span>, output_language=<span class="string">&quot;French&quot;</span>, text=<span class="string">&quot;I love programming.&quot;</span>).to_messages()</span><br></pre></td></tr></table></figure>



<h3 id="Example-Seletors"><a href="#Example-Seletors" class="headerlink" title="Example Seletors"></a>Example Seletors</h3><p>我们也可以创建一个示例库，在需要的时候从中选择其中若干个到 Prompt 中。ExampleSelector 就是负责做这类事情的。<br>基本的 ExampleSelector 信息定义如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BaseExampleSelector</span>(<span class="title class_ inherited__">ABC</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Interface for selecting examples to include in prompts.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @abstractmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">select_examples</span>(<span class="params">self, input_variables: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">str</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">dict</span>]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Select which examples to use based on the inputs.&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>如上，我们需要实现 <code>select_examples</code> 方法。接下来，让我们实现一个：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts.example_selector.base <span class="keyword">import</span> BaseExampleSelector</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Dict</span>, <span class="type">List</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CustomExampleSelector</span>(<span class="title class_ inherited__">BaseExampleSelector</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, examples: <span class="type">List</span>[<span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">str</span>]]</span>):</span><br><span class="line">        self.examples = examples</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_example</span>(<span class="params">self, example: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">str</span>]</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Add new example to store for a key.&quot;&quot;&quot;</span></span><br><span class="line">        self.examples.append(example)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">select_examples</span>(<span class="params">self, input_variables: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">str</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">dict</span>]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Select which examples to use based on the inputs.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> np.random.choice(self.examples, size=<span class="number">2</span>, replace=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">examples = [</span><br><span class="line">    &#123;<span class="string">&quot;foo&quot;</span>: <span class="string">&quot;1&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;foo&quot;</span>: <span class="string">&quot;2&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;foo&quot;</span>: <span class="string">&quot;3&quot;</span>&#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize example selector.</span></span><br><span class="line">example_selector = CustomExampleSelector(examples)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Select examples</span></span><br><span class="line">example_selector.select_examples(&#123;<span class="string">&quot;foo&quot;</span>: <span class="string">&quot;foo&quot;</span>&#125;)</span><br><span class="line"><span class="comment"># -&gt; array([&#123;&#x27;foo&#x27;: &#x27;2&#x27;&#125;, &#123;&#x27;foo&#x27;: &#x27;3&#x27;&#125;], dtype=object)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Add new example to the set of examples</span></span><br><span class="line">example_selector.add_example(&#123;<span class="string">&quot;foo&quot;</span>: <span class="string">&quot;4&quot;</span>&#125;)</span><br><span class="line">example_selector.examples</span><br><span class="line"><span class="comment"># -&gt; [&#123;&#x27;foo&#x27;: &#x27;1&#x27;&#125;, &#123;&#x27;foo&#x27;: &#x27;2&#x27;&#125;, &#123;&#x27;foo&#x27;: &#x27;3&#x27;&#125;, &#123;&#x27;foo&#x27;: &#x27;4&#x27;&#125;]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Select examples</span></span><br><span class="line">example_selector.select_examples(&#123;<span class="string">&quot;foo&quot;</span>: <span class="string">&quot;foo&quot;</span>&#125;)</span><br><span class="line"><span class="comment"># -&gt; array([&#123;&#x27;foo&#x27;: &#x27;1&#x27;&#125;, &#123;&#x27;foo&#x27;: &#x27;4&#x27;&#125;], dtype=object)</span></span><br></pre></td></tr></table></figure>


<h2 id="Indexes"><a href="#Indexes" class="headerlink" title="Indexes"></a>Indexes</h2><p>通过 Indexes，可以构建和 LLMs 更好地与 documents 进行交互。<br>indexes 最常用在检索中。<br>可以通过 <code>BaseRetriever</code> 来了解 Retriever 的定义：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> abc <span class="keyword">import</span> ABC, abstractmethod</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span></span><br><span class="line"><span class="keyword">from</span> langchain.schema <span class="keyword">import</span> Document</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BaseRetriever</span>(<span class="title class_ inherited__">ABC</span>):</span><br><span class="line"><span class="meta">    @abstractmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_relevant_documents</span>(<span class="params">self, query: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[Document]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Get texts relevant for a query.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            query: string to find relevant texts for</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            List of relevant documents</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p>默认情况下，LangChain 使用 <a target="_blank" rel="noopener" href="https://python.langchain.com/en/latest/ecosystem/chroma.html"><code>Chroma</code></a> 作为向量存储索引，我们也使用它来完成 indexes 的应用实例。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install chromadb </span><br></pre></td></tr></table></figure>
<p>关于 documents 的问答，通常包括四个步骤：</p>
<ul>
<li>创建索引</li>
<li>为该索引创建一个检索器 Retriever</li>
<li>创建问答链</li>
<li>问问题</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> RetrievalQA</span><br><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain.document_loaders <span class="keyword">import</span> TextLoader</span><br><span class="line">loader = TextLoader(<span class="string">&#x27;../state_of_the_union.txt&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>接下来创建索引</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.indexes <span class="keyword">import</span> VectorstoreIndexCreator</span><br><span class="line"></span><br><span class="line">index = VectorstoreIndexCreator().from_loaders([loader])</span><br></pre></td></tr></table></figure>
<p>index 已经被创建，现在我们就可以使用它来提问了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">query = <span class="string">&quot;What did the president say about Ketanji Brown Jackson&quot;</span></span><br><span class="line">index.query(query)</span><br><span class="line"></span><br><span class="line">query = <span class="string">&quot;What did the president say about Ketanji Brown Jackson&quot;</span></span><br><span class="line">index.query_with_sources(query)</span><br></pre></td></tr></table></figure>

<p><code>VectorstoreIndexCreator</code> 做了什么呢？<br>当 documents 被载入后：</p>
<ol>
<li>把 documents 分割成块，即若干个 document；</li>
<li>为每个 document 创建一个 embeddings；</li>
<li>在 vectorstore 中存储 documents 和 embeddings。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> CharacterTextSplitter</span><br><span class="line"><span class="keyword">from</span> langchain.embeddings <span class="keyword">import</span> OpenAIEmbeddings</span><br><span class="line"><span class="keyword">from</span> langchain.vectorstores <span class="keyword">import</span> Chroma</span><br><span class="line"></span><br><span class="line">text_splitter = CharacterTextSplitter(chunk_size=<span class="number">1000</span>, chunk_overlap=<span class="number">0</span>)</span><br><span class="line">documents = loader.load()</span><br><span class="line">texts = text_splitter.split_documents(documents)</span><br><span class="line">embeddings = OpenAIEmbeddings()</span><br><span class="line"></span><br><span class="line">db = Chroma.from_documents(texts, embeddings)</span><br><span class="line"><span class="comment"># 通过 retriever 暴露 index</span></span><br><span class="line">retriever = db.as_retriever()</span><br><span class="line"></span><br><span class="line">qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=<span class="string">&quot;stuff&quot;</span>, retriever=retriever)</span><br><span class="line"></span><br><span class="line">query = <span class="string">&quot;What did the president say about Ketanji Brown Jackson&quot;</span></span><br><span class="line">qa.run(query)</span><br></pre></td></tr></table></figure>

<p><code>VectorstoreIndexCreator</code> 实际上就是上述逻辑的封装。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">index_creator = VectorstoreIndexCreator(</span><br><span class="line">    vectorstore_cls=Chroma, </span><br><span class="line">    embedding=OpenAIEmbeddings(),</span><br><span class="line">    text_splitter=CharacterTextSplitter(chunk_size=<span class="number">1000</span>, chunk_overlap=<span class="number">0</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h2 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h2><p>默认情况，Chains 和 Agents 都是无状态的。在有些应用中，上下文是十分重要的，比如聊天机器人。<br>LangChain 提供了两种形式的 Memory 组件。首先，LangChain 提供了一些帮助工具以管理、操作先前的 chat messages；其次，LangChain 提供了简单的方式将这些工具集成到 Chains 中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ChatMessageHistory</span><br><span class="line"></span><br><span class="line">history = ChatMessageHistory()</span><br><span class="line"></span><br><span class="line">history.add_user_message(<span class="string">&quot;hi!&quot;</span>)</span><br><span class="line"></span><br><span class="line">history.add_ai_message(<span class="string">&quot;whats up?&quot;</span>)</span><br><span class="line">history.messages</span><br><span class="line"></span><br><span class="line">[HumanMessage(content=<span class="string">&#x27;hi!&#x27;</span>, additional_kwargs=&#123;&#125;),</span><br><span class="line"> AIMessage(content=<span class="string">&#x27;whats up?&#x27;</span>, additional_kwargs=&#123;&#125;)]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> ConversationChain</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">llm = OpenAI(temperature=<span class="number">0</span>)</span><br><span class="line">conversation = ConversationChain(</span><br><span class="line">    llm=llm, </span><br><span class="line">    verbose=<span class="literal">True</span>, </span><br><span class="line">    memory=ConversationBufferMemory()</span><br><span class="line">)</span><br><span class="line">conversation.predict(<span class="built_in">input</span>=<span class="string">&quot;Hi there!&quot;</span>)</span><br><span class="line"></span><br><span class="line">conversation.predict(<span class="built_in">input</span>=<span class="string">&quot;I&#x27;m doing well! Just having a conversation with an AI.&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="Chains"><a href="#Chains" class="headerlink" title="Chains"></a>Chains</h3><p>单独使用 LLM 完成一个简单的示例是没有问题的，但通常，更复杂的环境下，我们需要链式的 LLMs。<br>Chains 允许我们将多个组件组合在一起，创建一个单一的、连贯的应用。比如，我们可以创建一个使用 <code>PromptTemplate</code> 对用户输入进行格式化，将格式化后的数据传入到 LLM，最后接受格式化输出的链。<br>LangChain 提供了 Chains 的标准接口，以及一些通用的功能。LLMChain 就是一个简单的 Chain 的实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> LLMChain</span><br><span class="line"><span class="keyword">from</span> langchain.chat_models <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langchain.prompts.chat <span class="keyword">import</span> (</span><br><span class="line">    ChatPromptTemplate,</span><br><span class="line">    HumanMessagePromptTemplate,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">llm = OpenAI(temperature=<span class="number">0.9</span>)</span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;product&quot;</span>],</span><br><span class="line">    template=<span class="string">&quot;What is a good name for a company that makes &#123;product&#125;?&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">chain = LLMChain(llm=llm, prompt=prompt)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run the chain only specifying the input variable.</span></span><br><span class="line"><span class="built_in">print</span>(chain.run(<span class="string">&quot;colorful socks&quot;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">human_message_prompt = HumanMessagePromptTemplate(</span><br><span class="line">        prompt=PromptTemplate(</span><br><span class="line">            template=<span class="string">&quot;What is a good name for a company that makes &#123;product&#125;?&quot;</span>,</span><br><span class="line">            input_variables=[<span class="string">&quot;product&quot;</span>],</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line">chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])</span><br><span class="line">chat = ChatOpenAI(temperature=<span class="number">0.9</span>)</span><br><span class="line">chain = LLMChain(llm=chat, prompt=chat_prompt_template)</span><br><span class="line"><span class="built_in">print</span>(chain.run(<span class="string">&quot;colorful socks&quot;</span>))</span><br></pre></td></tr></table></figure>

<p>也可以通过将多个链组合在一起，构建一个更加复杂的链。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> SimpleSequentialChain</span><br><span class="line"></span><br><span class="line">second_prompt = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;company_name&quot;</span>],</span><br><span class="line">    template=<span class="string">&quot;Write a catchphrase for the following company: &#123;company_name&#125;&quot;</span>,</span><br><span class="line">)</span><br><span class="line">chain_two = LLMChain(llm=llm, prompt=second_prompt)</span><br><span class="line"></span><br><span class="line">overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run the chain specifying only the input variable for the first chain.</span></span><br><span class="line">catchphrase = overall_chain.run(<span class="string">&quot;colorful socks&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(catchphrase)</span><br></pre></td></tr></table></figure>


<h2 id="Agents"><a href="#Agents" class="headerlink" title="Agents"></a>Agents</h2><p>某些应用中，不仅仅使用一个预定义的 Chain 来链接 LLMs 或者其他工具进行工作，具体使用哪个 Chain 可能取决于用户的输入。这正是 Agents 出现的价值。<br>它通常会包含以下几个部分：</p>
<ul>
<li><p>Tools：agent 和外部世界进行交互的工具，比如 Google Search、数据库查询或者其他 Chains。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load the tool configs that are needed.</span></span><br><span class="line">search = SerpAPIWrapper()</span><br><span class="line">llm_math_chain = LLMMathChain(llm=llm, verbose=<span class="literal">True</span>)</span><br><span class="line">tools = [</span><br><span class="line">    Tool(</span><br><span class="line">        name = <span class="string">&quot;Search&quot;</span>,</span><br><span class="line">        func=search.run,</span><br><span class="line">        description=<span class="string">&quot;useful for when you need to answer questions about current events&quot;</span></span><br><span class="line">    ),</span><br><span class="line">    Tool(</span><br><span class="line">        name=<span class="string">&quot;Calculator&quot;</span>,</span><br><span class="line">        func=llm_math_chain.run,</span><br><span class="line">        description=<span class="string">&quot;useful for when you need to answer questions about math&quot;</span></span><br><span class="line">    )</span><br><span class="line">]</span><br><span class="line"><span class="comment"># Construct the agent. We will use the default agent type here.</span></span><br><span class="line"><span class="comment"># See documentation for a full list of options.</span></span><br><span class="line">agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=<span class="literal">True</span>)</span><br><span class="line">agent.run(<span class="string">&quot;Who is Leo DiCaprio&#x27;s girlfriend? What is her current age raised to the 0.43 power?&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">&gt; Entering new AgentExecutor chain...</span><br><span class="line"> I need to find out <span class="built_in">who</span> Leo DiCaprio<span class="string">&#x27;s girlfriend is and then calculate her age raised to the 0.43 power.</span></span><br><span class="line"><span class="string">Action: Search</span></span><br><span class="line"><span class="string">Action Input: &quot;Leo DiCaprio girlfriend&quot;</span></span><br><span class="line"><span class="string">Observation: Camila Morrone</span></span><br><span class="line"><span class="string">Thought: I now need to calculate her age raised to the 0.43 power</span></span><br><span class="line"><span class="string">Action: Calculator</span></span><br><span class="line"><span class="string">Action Input: 22^0.43</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&gt; Entering new LLMMathChain chain...</span></span><br><span class="line"><span class="string">22^0.43</span></span><br><span class="line"><span class="string">\```python</span></span><br><span class="line"><span class="string">import math</span></span><br><span class="line"><span class="string">print(math.pow(22, 0.43))</span></span><br><span class="line"><span class="string">\```</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Answer: 3.777824273683966</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&gt; Finished chain.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Observation: Answer: 3.777824273683966</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Thought: I now know the final answer</span></span><br><span class="line"><span class="string">Final Answer: Camila Morrone&#x27;</span>s age raised to the 0.43 power is 3.777824273683966.</span><br><span class="line"></span><br><span class="line">&gt; Finished chain.</span><br></pre></td></tr></table></figure>
</li>
<li><p>LLM：为 agent 赋能的语言模型。</p>
</li>
<li><p>Agents：决定该采取什么动作。</p>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://twitter.com/hwchase17/status/1595246702885507072">https://twitter.com/hwchase17/status/1595246702885507072</a><br><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/WkEi6Sea9IWgoei-w7MUzA">ChatGPT|LangChain Agent原理介绍</a><br><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/AizUBFssilX2S9aRfuz3_g">ChatGPT Prompt工程：设计、实践与思考</a><br><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/3coFhAdzr40tozn8f9Dc-w">LangChain：Model as a Service粘合剂，被ChatGPT插件干掉了吗？</a><br><a target="_blank" rel="noopener" href="https://python.langchain.com/en/latest/index.html">LangChain</a></p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    
      

    <span class="post-categories">
      <i class="icon-categories"></i>
        <a href="/categories/AI/">AI</a>
    </span>
    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tags/LangChain/">LangChain</a><a href="/tags/OpenAI/">OpenAI</a><a href="/tags/LLM/">LLM</a>
    </span>
    

    </div>

    
  </div>
</article>

  









    </main>

    <footer class="site-footer">
  <p class="site-info">
    
    &copy; 2024 YueGS
    
  </p>
</footer>
    
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-116967169-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-116967169-1');
</script>

    
  </div>
</div>
</body>
</html>